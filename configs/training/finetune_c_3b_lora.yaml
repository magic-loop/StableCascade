# GLOBAL STUFF
experiment_id: stage_c_3b_lora
checkpoint_path: null
output_path: /home/kevin/models/stable-cascade/lora_stage_c_bf16.safetensors
model_version: 3.6B

# WandB
wandb_project: StableCascade
wandb_entity: wandb_username

# TRAINING PARAMS
lr: 1.0e-4
batch_size: 1
image_size: 512
grad_accum_steps: 1
updates: 4000
backup_every: 1000
save_every: 1000
warmup_updates: 1
# use_fsdp: True -> FSDP doesn't work at the moment for LoRA
use_fsdp: False
cache_embeddings: True
max_cached_batches: 96

# GDF
# adaptive_loss_weight: True

# LoRA specific
module_filters: [".attn"]
rank: 16
train_tokens: null

# ema_start_iters: 5000
# ema_iters: 100
# ema_beta: 0.9

webdataset_path: file:/home/kevin/data/lifestyle_dataset_v2.tar
effnet_checkpoint_path: /home/kevin/models/stable-cascade/effnet_encoder.safetensors
previewer_checkpoint_path: /home/kevin/models/stable-cascade/previewer.safetensors
generator_checkpoint_path: /home/kevin/models/stable-cascade/stage_c_bf16.safetensors
